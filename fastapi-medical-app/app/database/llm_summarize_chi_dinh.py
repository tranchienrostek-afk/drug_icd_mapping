import argparse
import time
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# =========================
# CONFIG
# =========================
MODEL_NAME = "Qwen/Qwen2.5-1.5B-Instruct"
INPUT_CSV = "drug_data_final.csv"
OUTPUT_CSV = "drug_data_with_chi_dinh_tom_tat.csv"
CHI_DINH_COLUMN = "chi_dinh"

SYSTEM_PROMPT = """H√£y t√≥m t·∫Øt ch·ªâ ƒë·ªãnh ƒëi·ªÅu tr·ªã c·ªßa thu·ªëc sau th√†nh danh s√°ch ng·∫Øn c√°c b·ªánh ho·∫∑c tri·ªáu ch·ª©ng.
Y√™u c·∫ßu:
- Ti·∫øng Vi·ªát
- M·ªói m·ª•c 1‚Äì7 t·ª´
- NgƒÉn c√°ch b·∫±ng d·∫•u ph·∫©y
- Kh√¥ng gi·∫£i th√≠ch
- Kh√¥ng th√™m th√¥ng tin
"""

# =========================
# LOAD MODEL
# =========================
def load_model():
    print("üîπ Loading tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)

    print("üîπ Loading model (CPU)...")
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_NAME,
        torch_dtype=torch.float32,
        device_map="cpu",
        trust_remote_code=True
    )
    model.eval()
    return tokenizer, model


# =========================
# LLM SUMMARIZE
# =========================
def summarize_chi_dinh(tokenizer, model, chi_dinh_text: str) -> str:
    if not isinstance(chi_dinh_text, str) or chi_dinh_text.strip() == "":
        return ""

    prompt = f"""
{SYSTEM_PROMPT}

Ch·ªâ ƒë·ªãnh:
{chi_dinh_text}
"""

    inputs = tokenizer(
        prompt,
        return_tensors="pt",
        truncation=True,
        max_length=2048
    )

    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_new_tokens=64,
            do_sample=False,
            temperature=0.2
        )

    result = tokenizer.decode(output[0], skip_special_tokens=True)

    # ch·ªâ l·∫•y ph·∫ßn model sinh ra
    result = result.split("Ch·ªâ ƒë·ªãnh:")[-1].strip()
    return result


# =========================
# MAIN PIPELINE
# =========================
def main(limit: int):
    print("üîπ Reading CSV...")
    df = pd.read_csv(INPUT_CSV)

    if CHI_DINH_COLUMN not in df.columns:
        raise ValueError(f"Kh√¥ng t√¨m th·∫•y c·ªôt `{CHI_DINH_COLUMN}` trong CSV")

    if limit > 0:
        df = df.head(limit)

    tokenizer, model = load_model()

    summarized_results = []

    start_time = time.time()

    for idx, row in df.iterrows():
        chi_dinh = row.get(CHI_DINH_COLUMN, "")
        summary = summarize_chi_dinh(tokenizer, model, chi_dinh)
        summarized_results.append(summary)

        if (idx + 1) % 10 == 0:
            elapsed = time.time() - start_time
            print(f"‚è≥ ƒê√£ x·ª≠ l√Ω {idx + 1} d√≤ng | {elapsed/60:.2f} ph√∫t")

    df["chi_dinh_tom_tat"] = summarized_results

    print("üíæ Writing output CSV...")
    df.to_csv(OUTPUT_CSV, index=False, encoding="utf-8-sig")

    total_time = time.time() - start_time
    print(f"‚úÖ Ho√†n th√†nh | T·ªïng th·ªùi gian: {total_time/3600:.2f} gi·ªù")


# =========================
# ENTRY
# =========================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--limit",
        type=int,
        default=20,
        help="S·ªë d√≤ng c·∫ßn x·ª≠ l√Ω (test). D√πng 0 ƒë·ªÉ qu√©t to√†n b·ªô."
    )
    args = parser.parse_args()

    main(args.limit)
